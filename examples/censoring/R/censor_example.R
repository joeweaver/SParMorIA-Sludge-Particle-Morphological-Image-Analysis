################################################################################
# Example of non-destructive, explicit, and trackable censoring of whole files
# and individual particles in image analysis, supporting the paper 
# XXX title name XXX in JOVE XXX pub info XXX
#
# Joseph E. Weaver
# jeweave4@ncsu.edu
# joe.e.weaver@gmail.com
# NC State University
#
################################################################################

# Include packages --------------------------------------------------------
library("here")           # Portably manage directory locations relative to .Rproj
library("readr")          # For reading CSV files generated by SParMorIA
library("dplyr")          # For sensible management dataframes
library("tidyr")          # Bring in the entire tidyverse
library("purrr")          # Adds some functional programming
library("knitr")     # Output decent table

# Read in particle data from multiple csvs --------------------------------

# Use the here package to specify the location of the data directory
data_dir = here::here("data")

# Get a list of all CSV files in data dir
files <- dir(data_dir, pattern = "*.csv")

# Read each CSV file and combine all the particle data into one dataframe
# Inspired by the code listed at:
# http://serialmentor.com/blog/2016/6/13/reading-and-combining-many-tidy-data-files-in-R
data <- data_frame(filename = files) %>%
   mutate(file_contents = map(filename,
                              ~ read_csv(file.path(data_dir, .)))
   )
data <- unnest(data)

# Censor whole files  --------------------------------
# Keep track unique filenames and row count to track progress. If done
# interactively, you can also View() the relevant dataframes
cens_prog <- data.frame(remaining_particles=integer(),files=character(),operation=character())
cens_prog <- data.frame(remaining_particles=nrow(data),
                        files= unique(data$filename),
                        operation="Raw data")

# Read in our censoring specifciation
files_2_ignore <- read_csv(here("censor_files.csv"))

# Use dplyr to easily subset original dataframe
censored <- anti_join(data, files_2_ignore, by="filename")

# Record our progress
cens_prog <- bind_rows(cens_prog,data.frame(remaining_particles=nrow(censored),
                                            files= unique(censored$filename),
                                            operation="Remove whole file"))

# Censor individual particles  --------------------------------
# Read in our censoring specifciation
parts_2_ignore <- read_csv(here("censor_particles.csv"))

# A small, illustrative data issue here. FIJI does not provide a header name 
# for particle IDs, we have chosen to respect that format. When read by 
# read_csv, this column is given the header "X1". The corresponding column
# in the censoring file is "particleId".
# 
# One could either rename the columns to match, or use the following form
# of anti_join. Note how filename is still included, this ensures removing
# the particleID only from rows corresponding to the correct file. 
# (i.e. per-particle censoring requires both a particleId and filename to 
# uniquely identify a particle).

censored <- anti_join(censored, parts_2_ignore, 
                       by=c("filename"="filename","X1" = "particleId"))

# At this point, censored is ready to use for analysis, the remaining
# code produces a table showin the particle and file count from each
# censoring step

# Record our progress
cens_prog <- bind_rows(cens_prog,
                       data.frame(remaining_particles=nrow(censored),
                                 files= unique(censored$filename),
                                 operation="Remove individual particles"))

dt <- cens_prog %>% group_by(operation) %>% 
                  mutate(unique_files = n_distinct(files)) %>%
                  distinct(operation, remaining_particles, unique_files)


# Save progress as a table ------------------------------------------------
res <- kable(dt,"markdown") 
fileConn<-file(here::here("output","censor_results.txt"))
   writeLines(res, fileConn)
close(fileConn)

# Save our session info ------------------

sink(here::here("output", "censor_example.R.sessionInfo.txt"))
sessionInfo()
sink()
